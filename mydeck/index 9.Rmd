---
title       : "Week 9: Model Performance and Feature Engineering"
subtitle    : '`r format(Sys.Date(), "%m/%d/%Y")`'
author      : "Jake Campbell"
job         : 
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
widgets     : mathjax            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
---

```{r, echo=F, message=F, warning=F}
library(caret)
library(pROC)
library(yardstick)
library(MASS)
library(tidyverse)

data("mpg")
data("biopsy")

mpg_model <- lm(hwy ~ displ + cyl + drv, data = mpg)
biopsy_model <- glm(class ~ V1 + V5 + V7, data = biopsy, family = "binomial")

# For linear regression, we can look at resdiuals to determine
# model performance
mpg_output <- augment(mpg_model)
```

# Measuring Model Performance

- The main purpose of most predictive modeling problems is to make predictions
- It makes sense, than, to measure model performance off of our predictions
  + Using residuals with linear regression and predicted classes and probabilities with logistic regression

---

# Remember Overfitting

- We'll be looking at predictions made on our training data today
- These predictions are likely going to be better than we should actually expect
  + Our model has seen this data before
- Next class, we'll be going over cross-validation, allowing us to see how our model performs on new data

---

# Linear Regression Model Metrics

- MAE: Mean Absolute Error
  + Takes the average absolute value of your residuals
```{r}
mpg_output %>%
  mae(truth = hwy, estimate = .fitted)
```

---

# Linear Regression Model Metrics

- MSE: Mean Square Error
  + Takes the average of squared residuals
- RMSE: Root Mean Square Error
  + Takes the square root of the MSE
```{r}
mean(mpg_output$.resid^2)
mpg_output %>%
  rmse(truth = hwy, estimate = .fitted)
```

---

```{r, echo=F, message=F, warning=F}
biopsy_output <- augment(biopsy_model, type.predict = "prob") %>%
  mutate(.fitted_class = factor(ifelse(.fitted >= .5,
                                       "malignant", "benign"))) %>%
  dplyr::select(class, V1, V5, V7, .fitted, .fitted_class)
cm_biopsy <- xtabs(~ .fitted_class + class, data = biopsy_output)

set.seed(1234)
mpg <- mpg %>%
  mutate(price = paste("$", round(rnorm(n = 234, mean = 20000, sd = 5000),
                                  digits = 0), sep = "")) %>%
  mutate(production_date = sample(seq(as.Date('1998/01/01'),
                                      as.Date('2008/12/31'), by="day"), 234))
```

# Logistic Regression Metrics

- Accuracy: $$\frac{All Correct Predictions}{All Possible Predictions}$$
- True Positives and Negatives: predictions that were correct from the positive and negative class, respectively
- False Positives and Negatives: predictions that were predicted in the wrong class(positive and negative respectively)

---

# Logistic Regression Metrics

- Sensitivity: $$\frac{TP}{TP + FN}$$
  + Accuracy rate of the positive class
```{r}
options(yardstick.event_first = FALSE)
biopsy_output %>%
  sens(truth = class, estimate = .fitted_class)
```

---

# Logistic Regression Metrics

- Specificity: $$\frac{TN}{TN + FP}$$
  + Accuracy rate of the negative class
```{r}
options(yardstick.event_first = FALSE)
biopsy_output %>%
  spec(truth = class, estimate = .fitted_class)
```

---

# ROC and AUC

- ROC (Receiver Operating Characteristic) is a curve that plots the sensitivity and specificity at different predictive threshholds
  + By threshhold, we mean how to split our predictive probabilities into classes
  + Raising the threshhold increases our specificity and vice versa
- AUC (Area Under the Curve) is the area under the ROC curve
  + The closer AUC is to `1`, the better the classifier

---

# ROC and AUC

```{r, warning=F, message=F, fig.align='center'}
roc(response = biopsy_output$class,
    predictor = biopsy_output$.fitted, plot = T)
```

---

# Feature Engineering

- A lot of the time, predictors are not laid out in front of us
- We have to transform some features to have them actually be useful in our model
  + Ex: a specific date doesn't hold much predictive power, but a month could

---

# Splitting Text

- `str_split` can be used to split text off of some pattern
  + `str_split_fixed` returns a matrix instead of a list
```{r}
transmission <- str_split_fixed(string = mpg$trans, pattern = "[(]", n = 2)
head(transmission)
```

---

# Replacing Text

- `gsub` can be used to replace a certain character in text with another
  + A lot of times, you may want to replace a character with nothing, in which case, you would replace it with `""`
```{r}
mpg <- mpg %>%
  mutate(price = gsub(pattern = "[$]", replacement = "", price)) %>%
  mutate(price = as.numeric(price))
```

---

# Dealing with Dates

- Dates are a specific data type in R
- We can use `as.Date` to turn something into a date
  + We need to specify the `format` argument to say what order the date is in
  + By default, the format is `"%Y-%m-%d"` for full year, numeric month, and numeric day
  + For example: `2019-12-01`


---

# Dealing with Dates

- `format` is also a function we can use to pull a specific part of a date object out
```{r}
mpg <- mpg %>%
  mutate(month = format(x = production_date, "%m"),
         year = format(x = production_date, "%Y"),
         day = format(x = production_date, "%d"))
```